# Bazel Run

cd tensorflow

bazel run -c opt tensorflow/lite/toco:toco -- \
--input_file=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite8/tflite_graph.pb \
--output_file=/Users/woolee/mldl_project/github/coral_mask/1NN/quantized/one_nn8.tflite \
--input_shapes=1,320,320,3 \
--input_arrays=normalized_input_image_tensor \
--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \
--inference_type=QUANTIZED_UINT8 \
--allow_custom_ops \ 




# 1.
mask_model_train ; 모델 돌리면서 checkpoint 생성됨
mask_export_model ; frozen_graph 로 export

# 2.
참고 - https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter

# 3. Convert 후 돌리기
edgetpu_classify_server \
--model ${DEMO_FILES}/마스크넷tflite파일 \
--labels ${DEMO_FILES}/마스크label파일

참고 - https://coral.ai/docs/dev-board/camera/#using-a-streaming-server

0 - nomask, 1 - mask




$
edgetpu_classify_server \
--model ${DEMO_FILES}/마스크넷tflite파일 \
--labels ${DEMO_FILES}/마스크label파일


~/coral_mask/1NN/mask_model_export_tflite3/one_nn_edgetpu.tflite
~/coral_mask/1NN/mask_model_export_tflite3/one_nn_label.txt





# this worked
edgetpu_detect_server \
--model ~/coral_mask/1NN/mask_model_export_tflite3/one_nn_edgetpu.tflite \
--labels ~/coral_mask/1NN/mask_model_export_tflite3/one_nn_label.txt


edgetpu_detect_server \
--model ~/coral_mask/1NN/mask_model_export_tflite6/one_nn_edgetpu.tflite \
--labels ~/coral_mask/1NN/mask_model_export_tflite6/one_nn_label.txt

# gsds wifi named 'ambientai' address
192.168.0.23:4664

# gsds wifi named 'seminar_5g' address
192.168.0.20:4664

# wc home wifi named 'lwclwc' address
192.168.0.9:4664