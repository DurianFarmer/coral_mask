{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596618121119",
   "display_name": "Python 3.7.3 64-bit ('woopy37': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.2.0\n"
    }
   ],
   "source": [
    "import os as os\n",
    "import tensorflow as tf\n",
    "#import tensorflow.compat.v1 as tf\n",
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite'"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# referred https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir = \"./saved_model\" \n",
    "dir = \".\"\n",
    "#dir = \"./mask_model_export_tflite\" #/tflite_graph.pb\n",
    "#dir = \"./saved_model/variables\" \n",
    "#dir = \".\" #/frozen_inference_graph.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['tflite_graph.pbtxt', 'to_tflite.ipynb', 'tflite_graph.pb']"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "os.listdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite'"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tflite_graph.pb    tflite_graph.pbtxt to_tflite.ipynb\n"
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"./saved_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-04c51ee3bab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;31m# TODO(b/130297984): Add support for converting multiple function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_funcs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m       raise ValueError(\"This converter can only convert a single \"\n\u001b[0m\u001b[1;32m    453\u001b[0m                        \u001b[0;34m\"ConcreteFunction. Converting multiple functions is \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                        \"under development.\")\n",
      "\u001b[0;31mValueError\u001b[0m: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development."
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(dir)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export'"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'./saved_model'"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2020-08-04 19:19:13.065297: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2020-08-04 19:19:13.075155: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faaffe2ceb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2020-08-04 19:19:13.075183: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\nTraceback (most recent call last):\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/bin/tflite_convert\", line 8, in <module>\n    sys.exit(main())\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 638, in main\n    app.run(main=run_main, argv=sys.argv[:1])\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n    _run_main(main, args)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n    sys.exit(main(argv))\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 624, in run_main\n    _convert_tf1_model(tflite_flags)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 130, in _convert_tf1_model\n    converter = _get_toco_converter(flags)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 117, in _get_toco_converter\n    return converter_fn(**converter_kwargs)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 788, in from_frozen_graph\n    raise ValueError(\"input_shapes must be defined for this model.\")\nValueError: input_shapes must be defined for this model.\n"
    }
   ],
   "source": [
    "!tflite_convert \\\n",
    "    --output_file=/saved_model.tflite \\\n",
    "    --graph_def_file=./saved_model.pb \\\n",
    "    --input_arrays=None,None,None,3 \\\n",
    "    --output_arrays=output \\\n",
    "    --enable_v1_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/lite/convert/cmdline\n",
    "\n",
    "\n",
    "# ValueError: None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.\n",
    "# https://github.com/tensorflow/tensorflow/issues/22564 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\nI0802 21:17:09.435262 4635200960 saver.py:1512] Saver not created because there are no variables in the graph to restore\n2020-08-02 21:17:09.588881: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2020-08-02 21:17:09.599617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff3ca259230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2020-08-02 21:17:09.599633: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n2020-08-02 21:17:11.062585: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\n2020-08-02 21:17:11.062665: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n2020-08-02 21:17:11.189382: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n2020-08-02 21:17:11.189406: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\n2020-08-02 21:17:11.189410: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\n2020-08-02 21:17:13.294911: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\n2020-08-02 21:17:13.294983: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n2020-08-02 21:17:13.701780: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n2020-08-02 21:17:13.701801: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 1669 nodes (-1267), 2101 edges (-1432), time = 237.074ms.\n2020-08-02 21:17:13.701805: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 1669 nodes (0), 2101 edges (0), time = 58.302ms.\nTraceback (most recent call last):\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/bin/tflite_convert\", line 8, in <module>\n    sys.exit(main())\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 638, in main\n    app.run(main=run_main, argv=sys.argv[:1])\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n    _run_main(main, args)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n    sys.exit(main(argv))\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 621, in run_main\n    _convert_tf2_model(tflite_flags)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 237, in _convert_tf2_model\n    tflite_model = converter.convert()\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 483, in convert\n    _get_tensor_name(tensor), shape_list))\nValueError: None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.\n"
    }
   ],
   "source": [
    "!tflite_convert \\\n",
    "  --saved_model_dir=./saved_model \\\n",
    "  --output_file=./saved_model/onenn.tflite \\\n",
    "  --input_shape=None,None,None,3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d4045ca9a5a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_input_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_output_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converted_model.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;31m# TODO(b/130297984): Add support for converting multiple function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_funcs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m       raise ValueError(\"This converter can only convert a single \"\n\u001b[0m\u001b[1;32m    453\u001b[0m                        \u001b[0;34m\"ConcreteFunction. Converting multiple functions is \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                        \"under development.\")\n",
      "\u001b[0;31mValueError\u001b[0m: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# This ensures that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Traceback (most recent call last):\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/bin/tflite_convert\", line 8, in <module>\n    sys.exit(main())\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 638, in main\n    app.run(main=run_main, argv=sys.argv[:1])\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n    _run_main(main, args)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n    sys.exit(main(argv))\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 621, in run_main\n    _convert_tf2_model(tflite_flags)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 228, in _convert_tf2_model\n    converter = lite.TFLiteConverterV2.from_saved_model(flags.saved_model_dir)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 399, in from_saved_model\n    saved_model = _load(saved_model_dir, tags)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 578, in load\n    return load_internal(export_dir, tags)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 588, in load_internal\n    loader_impl.parse_saved_model_with_debug_info(export_dir))\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 56, in parse_saved_model_with_debug_info\n    saved_model = _parse_saved_model(export_dir)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 113, in parse_saved_model\n    constants.SAVED_MODEL_FILENAME_PB))\nOSError: SavedModel file does not exist at: =/{saved_model.pbtxt|saved_model.pb}\n"
    }
   ],
   "source": [
    "!tflite_convert \\\n",
    "    --graph_def_file=graph_def_file= /Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/saved_model.pb \\\n",
    "    --output_file=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/saved_model.pbtxt \\\n",
    "    --output_format=TFLITE \\\n",
    "    --input_arrays=normalized_input_image_tensor \\\n",
    "    --input_shapes=1,300,300,3 \\\n",
    "    --inference_type=FLOAT \\\n",
    "    --output_arrays=\"\" \\\n",
    "    --allow_custom_ops \\\n",
    "    --saved_model_dir =  /saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'.'"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-04c51ee3bab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;31m# TODO(b/130297984): Add support for converting multiple function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_funcs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m       raise ValueError(\"This converter can only convert a single \"\n\u001b[0m\u001b[1;32m    453\u001b[0m                        \u001b[0;34m\"ConcreteFunction. Converting multiple functions is \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                        \"under development.\")\n",
      "\u001b[0;31mValueError\u001b[0m: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development."
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(dir)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bazel run -c opt tensorflow/lite/toco:toco -- \\\n",
    "--input_file=$/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/tflite_graph.pb \\\n",
    "--output_file=$/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/detect.tflite \\\n",
    "--input_shapes=1,320,320,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=QUANTIZED_UINT8 \\\n",
    "--mean_values=128 \\\n",
    "--std_values=128 \\\n",
    "--change_concat_input_ranges=false \\\n",
    "--allow_custom_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bazel run -c opt tensorflow/lite/toco:toco -- \\\n",
    "--input_file=$/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/tflite_graph.pb \\\n",
    "--output_file=$/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/detect.tflite \\\n",
    "--input_shapes=1,320,320,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=QUANTIZED_UINT8 \\\n",
    "--mean_values=128 \\\n",
    "--std_values=128 \\\n",
    "--change_concat_input_ranges=false \\\n",
    "--allow_custom_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bazel run -c opt tensorflow/lite/toco:toco -- \\\n",
    "--input_file=$/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/tflite_graph.pb \\\n",
    "--output_file=$/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/detect.tflite \\\n",
    "--input_shapes=1,320,320,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=QUANTIZED_UINT8 \\\n",
    "--mean_values=128 \\\n",
    "--std_values=128 \\\n",
    "--change_concat_input_ranges=false \\\n",
    "--allow_custom_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bazel 3.1.0 required\n",
    "# cd \"/Users/woolee/.bazel/bin\" && curl -LO https://releases.bazel.build/3.1.0/release/bazel-3.1.0-darwin-x86_64 && chmod +x bazel-3.1.0-darwin-x86_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bazel run -c opt tensorflow/lite/toco:toco -- \\\n",
    "--input_file=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/tflite_graph.pb \\\n",
    "--output_file=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/detect.tflite \\\n",
    "--input_shapes=1,320,320,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=QUANTIZED_UINT8 \\\n",
    "--mean_values=128 \\\n",
    "--std_values=128 \\\n",
    "--change_concat_input_ranges=false \\\n",
    "--allow_custom_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bazel run -c opt tensorflow/lite/toco:toco -- \\\n",
    "--input_file=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/tflite_graph.pb \\\n",
    "--output_file=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/one_nn.tflite \\\n",
    "--input_shapes=1,320,320,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2' \\\n",
    "--inference_type=QUANTIZED_UINT8 \\\n",
    "--mean_values=128 \\\n",
    "--std_values=128 \\\n",
    "--change_concat_input_ranges=false \\\n",
    "--allow_custom_ops\n",
    "#this worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-83c6cf5ce9d9>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-83c6cf5ce9d9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    bazel run -c opt tensorflow/lite/toco:toco -- \\\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "bazel run -c opt tensorflow/lite/toco:toco -- \\\n",
    "--input_file=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/tflite_graph.pb \\\n",
    "--output_file=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/one_nn.tflite \\\n",
    "--input_shapes=1,320,320,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-3a4cd7886abc>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-3a4cd7886abc>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    bazel run -c opt tensorflow/lite/toco:toco -- \\\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "bazel run -c opt tensorflow/lite/toco:toco -- \\\n",
    "--input_file=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/tflite_graph.pb \\\n",
    "--output_file=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite/one_nn.tflite \\\n",
    "--input_shapes=1,320,320,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\\n",
    "--inference_type=QUANTIZED_UINT8 \\\n",
    "--default_ranges_max= True \\\n",
    "--default_ranges_min= True \\\n",
    "--allow_custom_ops \\ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bazel run -c opt tensorflow/lite/toco:toco -- \\\n",
    "--input_file=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite4/tflite_graph.pb \\\n",
    "--output_file=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite4/one_nn.tflite \\\n",
    "--input_shapes=1,320,320,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\\n",
    "--inference_type=QUANTIZED_UINT8 \\\n",
    "--allow_custom_ops \\ \n",
    "\n",
    "\n",
    "### 실행시 에러 ###\n",
    "# INFO: Build completed successfully, 3011 total actions\n",
    "# 2020-08-05 19:58:52.619204: I tensorflow/lite/toco/import_tensorflow.cc:663] Converting unsupported operation: TFLite_Detection_PostProcess\n",
    "# 2020-08-05 19:58:52.656717: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 901 operators, 1328 arrays (0 quantized)\n",
    "# 2020-08-05 19:58:52.681300: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 901 operators, 1328 arrays (0 quantized)\n",
    "# 2020-08-05 19:58:52.732246: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 123 operators, 308 arrays (1 quantized)\n",
    "# 2020-08-05 19:58:52.734621: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 123 operators, 308 arrays (1 quantized)\n",
    "# 2020-08-05 19:58:52.735904: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 123 operators, 308 arrays (1 quantized)\n",
    "# 2020-08-05 19:58:52.737746: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 123 operators, 308 arrays (1 quantized)\n",
    "# 2020-08-05 19:58:52.739330: F tensorflow/lite/toco/tooling_util.cc:1734] Array FeatureExtractor/MobilenetV2/Conv/Relu6, which is an input to the Pad operator producing the output array FeatureExtractor/MobilenetV2/expanded_conv/Pad, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\n",
    "# zsh: abort      bazel run -c opt tensorflow/lite/toco:toco --   --input_shapes=1,320,320,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bazel run //tensorflow/lite/python:tflite_convert -- \\\n",
    "  --saved_model_dir=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite2/tflite_graph.pb \\\n",
    "  --output_file=/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite2/one_nn.tflite \\\n",
    "\n",
    "### 실행시 에러 ###\n",
    "# RuntimeError: MetaGraphDef associated with tags {'serve'} could not be found in SavedModel. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli` available_tags: [set()]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android#bazel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/lite/convert/cmdline\n",
    "# https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md\n",
    "# https://www.tensorflow.org/install/source#download_the_tensorflow_source_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = \"/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export_tflite\""
   ]
  }
 ]
}