{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596367837451",
   "display_name": "Python 3.7.3 64-bit ('woopy37': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.2.0\n"
    }
   ],
   "source": [
    "import os as os\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export'"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# referred https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"./saved_model\" \n",
    "#dir = \"./saved_model/variables\" \n",
    "#dir = \".\" #/frozen_inference_graph.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-04c51ee3bab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    481\u001b[0m               \u001b[0;34m\"None is only supported in the 1st dimension. Tensor '{0}' has \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m               \"invalid shape '{1}'.\".format(\n\u001b[0;32m--> 483\u001b[0;31m                   _get_tensor_name(tensor), shape_list))\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mshape_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshape_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m           \u001b[0;31m# Set the batch size to 1 if undefined.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'."
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(dir)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/Users/woolee/mldl_project/github/coral_mask/1NN/mask_model_export'"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'./saved_model'"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2020-08-02 20:57:19.822235: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2020-08-02 20:57:19.832037: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff2e1d75350 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2020-08-02 20:57:19.832075: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\nIgnore 'tcmalloc: large alloc' warnings.\nTraceback (most recent call last):\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 749, in from_frozen_graph\n    graph_def.ParseFromString(file_content)\ngoogle.protobuf.message.DecodeError: Error parsing message\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/bin/tflite_convert\", line 8, in <module>\n    sys.exit(main())\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 638, in main\n    app.run(main=run_main, argv=sys.argv[:1])\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n    _run_main(main, args)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n    sys.exit(main(argv))\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 624, in run_main\n    _convert_tf1_model(tflite_flags)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 130, in _convert_tf1_model\n    converter = _get_toco_converter(flags)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 117, in _get_toco_converter\n    return converter_fn(**converter_kwargs)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 758, in from_frozen_graph\n    file_content = six.ensure_text(file_content, \"utf-8\")\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/six.py\", line 935, in ensure_text\n    return s.decode(encoding, errors)\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xfc in position 5: invalid start byte\n"
    }
   ],
   "source": [
    "!tflite_convert \\\n",
    "    --output_file=/saved_model.tflite \\\n",
    "    --graph_def_file=./saved_model/saved_model.pb \\\n",
    "    --input_arrays=input \\\n",
    "    --output_arrays=output \\\n",
    "    --enable_v1_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/lite/convert/cmdline\n",
    "\n",
    "\n",
    "# ValueError: None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.\n",
    "# https://github.com/tensorflow/tensorflow/issues/22564 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\nI0802 21:17:09.435262 4635200960 saver.py:1512] Saver not created because there are no variables in the graph to restore\n2020-08-02 21:17:09.588881: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2020-08-02 21:17:09.599617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff3ca259230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2020-08-02 21:17:09.599633: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n2020-08-02 21:17:11.062585: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\n2020-08-02 21:17:11.062665: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n2020-08-02 21:17:11.189382: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n2020-08-02 21:17:11.189406: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.\n2020-08-02 21:17:11.189410: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\n2020-08-02 21:17:13.294911: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\n2020-08-02 21:17:13.294983: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n2020-08-02 21:17:13.701780: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n2020-08-02 21:17:13.701801: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 1669 nodes (-1267), 2101 edges (-1432), time = 237.074ms.\n2020-08-02 21:17:13.701805: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 1669 nodes (0), 2101 edges (0), time = 58.302ms.\nTraceback (most recent call last):\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/bin/tflite_convert\", line 8, in <module>\n    sys.exit(main())\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 638, in main\n    app.run(main=run_main, argv=sys.argv[:1])\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n    _run_main(main, args)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n    sys.exit(main(argv))\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 621, in run_main\n    _convert_tf2_model(tflite_flags)\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 237, in _convert_tf2_model\n    tflite_model = converter.convert()\n  File \"/Users/woolee/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 483, in convert\n    _get_tensor_name(tensor), shape_list))\nValueError: None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.\n"
    }
   ],
   "source": [
    "!tflite_convert \\\n",
    "  --saved_model_dir=./saved_model \\\n",
    "  --output_file=./saved_model/onenn.tflite \\\n",
    "  --input_shape=None,None,None,3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d4045ca9a5a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_input_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_output_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converted_model.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/woopy37/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    481\u001b[0m               \u001b[0;34m\"None is only supported in the 1st dimension. Tensor '{0}' has \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m               \"invalid shape '{1}'.\".format(\n\u001b[0;32m--> 483\u001b[0;31m                   _get_tensor_name(tensor), shape_list))\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mshape_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshape_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m           \u001b[0;31m# Set the batch size to 1 if undefined.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# This ensures that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}